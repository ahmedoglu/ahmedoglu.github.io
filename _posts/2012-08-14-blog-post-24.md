---
title: 'When Data Replaces Dignity: A Critique of Rationalism in Politics and War'
date: 2025-03-28
permalink: /posts/2012/08/blog-post-24/
tags:
  - Dignity
  - Humans
  - Rationalism
---

As human beings, we like to make sense of the world around us. We connect this thing to that thing, we draw a map in our minds that helps us navigate life and make decisions. But often, that map starts with a simple metaphor — and slowly, over time, that metaphor turns into a “truth” in our minds.
Take, for example: “The brain is like a computer.” That was originally just a scientific analogy, meant to help explain a complex idea. But over time, we started treating the brain as if it literally were a computer. And we forgot that, at the end of the day, we are human — not machines.

Antoine Bousquet (a scholar focusing on society and technology) draws attention to exactly this point. He says that in the 20th century, especially after World War II, there was a shift in the way people thought.
It started with scientists like Claude Shannon (founder of information theory), who was working on purely technical problems — like how to send a message from one place to another with the least amount of distortion. No philosophical or human depth in that.
But then came people like Norbert Wiener (the father of cybernetics), who expanded these ideas and applied them to much broader topics: how the brain works, how humans behave, even how society functions.

The problem isn’t that they expanded the idea — the problem is that people started believing in it as if it were a fact.
We began hearing things like: “Humans are just information systems,” or “The brain calculates, takes inputs, gives outputs.”
And in doing so, we forgot about feelings, about consciousness, about the soul, about irrational decisions.
We began treating human beings like Excel sheets — and if your numbers don’t add up, then you’re the problem.

That same logic also entered politics and warfare.
During the Cold War, a concept called “Game Theory” emerged — basically treating states like players in a game of chess or poker, where every move is calculated in terms of gains and losses.
The U.S. actually applied this in Vietnam: they said, “If we hit them hard enough, they’ll back down.”
But they forgot something: the Vietnamese weren’t thinking the same way. These were people who had been fighting for their independence for decades. For them, resistance wasn’t just war — it was dignity, it was history, it was about the future of their children.

So you can’t use the same measuring stick for everything.
It’s like assuming your enemy will think exactly like you — that if you apply pressure, they’ll surrender.
It’s like saying, “If we raise salaries, people will work harder,” without asking: where do people want to work? How do they feel about their work

Do they feel any value in what they’re doing?
These models often forget: we’re not just numbers. We’re people.

Antoine also points out something crucial: war itself has changed. In the past, the soldier would go to the battlefield, look the enemy in the eye, and make life-or-death decisions.
Now?
A soldier might be sitting in an air-conditioned room, operating a drone, hitting a target thousands of kilometers away — without ever seeing the enemy, without even feeling like they’re in a war.
Where’s the courage in that?
Where’s the sense of risk?
Where’s that heart-driven decision-making?

What’s strange is that even armies aren’t united on this.
Some high-ranking military officials are thrilled by the idea of “smart war,” where you achieve results with no losses.
But there are still those — like the U.S. Marines — who believe the real battlefield is what reveals the true character of a soldier.
For them, the essence of combat isn’t in the software, it’s in the sweat, the mess, the chaos.

And perhaps the most dangerous thing Antoine says is this:
The way technology has entered the military has caused a crisis of identity.
Is the army still the institution that defends the homeland with blood and honor?
Or is it just a team of engineers and analysts tracking performance metrics on screens?

This leads us to a bigger question:
How do we think?
What are our decisions based on?
Do we really understand humans, states, and battlefields — or are we just building entire theories on old metaphors we forgot were just metaphors?

The problem isn’t just that we believed in scientific analogies — it’s also that we started applying them to everything without asking if they even fit.

Like in politics…

We hear a lot about “smart governance,” “digital states,” “technological solutions.”
But here’s the real question:
Is a state really a company?
Is a citizen just a data point?

Or are we fooling ourselves — trying to force the human world, with all its depth, emotion, and history — into neat mathematical models that are comfortable, but ultimately not real?

We see this in many of the political decisions made around us.
They look rational on paper, but fail dramatically in reality — because they assume the public is a single, logical unit.

Take, for example, the idea that “if you apply economic pressure, people will adapt.”
But in reality, what happens?
People may stay silent… but anger builds. And one day, unexpectedly, it explodes.

The model-makers forget that humans have pride, frustration, broken spirits — emotional layers that don’t fit in spreadsheets.
Sometimes, one person crossing the street, saying the right thing at the right time, can ignite a whole nation.

Even in education, we reduce students to numbers in a system.
We measure their “quality” by test scores and forget that maybe that kid has a hidden talent that exams don’t show.
Or maybe that girl thinks outside the box, but doesn’t have a space to express it.
We end up producing generations who memorize but don’t understand, who are educated but not creative.
All because we believed humans can be put in a single “category” — and that intelligence = results.

And in war? Same logic.
A country thinks: “If we strike hard enough, the enemy will submit.”
So they bomb, detain, destroy — thinking it’s all about deterrence.
But years later, they realize the opposite happened: repression increased anger, not fear.
Because people don’t always get scared. Sometimes they explode.

Just look at Palestine, Iraq, Syria…
Their homes were destroyed, their families displaced, they were told “this is to teach you a lesson.”
But what happened?
They became fiercer, braver, more defiant — even knowing they might die.
Because in their eyes, dying with dignity is better than living in humiliation.

And all this brings us back to Antoine Bousquet’s original warning:

We took tools that were made for technical problems… and used them to understand human beings.

And in thinking we were getting closer to understanding — we actually moved further away.

A human being is not an equation.
Politics is not an assembly line.
Society is not an algorithm.

So we need to ask ourselves:
Why are we so eager to believe the easy stories?
Why are we so comfortable with the idea that “the world can be understood by logic alone”?

And maybe, just maybe…
It’s time to start again.
To put the human being back at the center — and rethink everything from there.
